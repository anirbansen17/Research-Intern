{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 0 with 4000 samples.\n",
      "Minority class: 1 with 2000 samples.\n",
      "Minority class: 2 with 1000 samples.\n",
      "Minority class: 3 with 750 samples.\n",
      "Minority class: 4 with 500 samples.\n",
      "Minority class: 5 with 350 samples.\n",
      "Minority class: 6 with 200 samples.\n",
      "Minority class: 7 with 100 samples.\n",
      "Minority class: 8 with 60 samples.\n",
      "Minority class: 9 with 40 samples.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial import distance\n",
    "import skfuzzy as fuzz  \n",
    "\n",
    "\n",
    "\n",
    "# Fuzzy C-Means Clustering Function\n",
    "def Fuzzy(X, m):\n",
    "    \"\"\"\n",
    "    Perform Fuzzy C-Means clustering on the majority class elements X.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Majority class data (numpy array or equivalent)\n",
    "    - m: Number of components (clusters)\n",
    "\n",
    "    Returns:\n",
    "    - centroids: m centroids obtained from Fuzzy C-Means\n",
    "    \"\"\"\n",
    "    \n",
    "    X_transposed = X.T\n",
    "    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "        X_transposed, m, 2, error=0.005, maxiter=1000, init=None\n",
    "    )\n",
    "\n",
    "    return cntr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to perform GMM and return the mixture parameters\n",
    "def GMM(X, m):\n",
    "    centroids = Fuzzy(X, m)\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=m, means_init=centroids)\n",
    "    gmm.fit(X)\n",
    "    \n",
    "    return gmm.means_, gmm.covariances_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate new samples based on Gaussian sampling\n",
    "def Sample(mu, sigma, n_samples):\n",
    "    return np.random.multivariate_normal(mu, sigma, n_samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main function \n",
    "def augment_data(X_majority, X_minority, k=3):\n",
    "    M = len(X_majority)  \n",
    "    GEN = []  \n",
    "    \n",
    "    for class_c_data in X_minority:      \n",
    "        n_c = len(class_c_data)\n",
    "        m = M / n_c  # ratio\n",
    "\n",
    "        # Perform GMM on majority class \n",
    "        mu, sigma = GMM(X_majority, int(m))\n",
    "\n",
    "        genc = [] \n",
    "\n",
    "        if m > k:\n",
    "            # Case when m > k\n",
    "            for x in class_c_data:\n",
    "                # Find k-nearest centroids (mu's)\n",
    "                dists = [distance.euclidean(x, mu_i) for mu_i in mu]\n",
    "                k_nearest_indices = np.argsort(dists)[:k]\n",
    "                mu_k = mu[k_nearest_indices]\n",
    "                sigma_k = sigma[k_nearest_indices]\n",
    "\n",
    "                # Calculate mux and sigmax\n",
    "                mux = (np.sum(mu_k, axis=0) + x) / (k + 1)\n",
    "                sigmax = (np.sum(sigma_k, axis=0) + np.cov(class_c_data.T)) / (k + 1)\n",
    "\n",
    "                # Number of samples to generate for each element\n",
    "                n_to_generate = int((M - n_c) / n_c)\n",
    "                gen_x = Sample(mux, sigmax, n_to_generate)\n",
    "\n",
    "                genc.append(gen_x)\n",
    "\n",
    "        else:\n",
    "            # Case when m < k\n",
    "            n_comp = int(M / n_c)\n",
    "            mu_comp, sigma_comp = GMM(class_c_data, n_comp)\n",
    "\n",
    "            for mu_i, sigma_i in zip(mu_comp, sigma_comp):\n",
    "                n_to_generate = int(n_c * (M / n_comp))\n",
    "                gen_comp = Sample(mu_i, sigma_i, n_to_generate)\n",
    "                genc.append(gen_comp)\n",
    "        \n",
    "        GEN.append(genc)\n",
    "    \n",
    "    return GEN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load datasets \n",
    "features = torch.load('imbalanced_train_features.pt')  \n",
    "labels = torch.load('imbalanced_train_labels.pt')     \n",
    "\n",
    "# Function to find majority and minority classes\n",
    "def prepare_data(features, labels):\n",
    "    \n",
    "    unique_classes, class_counts = torch.unique(labels, return_counts=True)\n",
    "    \n",
    "    # find Majority class \n",
    "    majority_class = unique_classes[torch.argmax(class_counts)]\n",
    "    X_majority = features[labels == majority_class].numpy()  \n",
    "\n",
    "    # find minority classes\n",
    "    X_minority = [features[labels == uc].numpy() for uc in unique_classes if uc != majority_class]\n",
    "\n",
    "    \n",
    "    print(f\"Majority class: {majority_class.item()} with {class_counts[torch.argmax(class_counts)].item()} samples.\")\n",
    "    for uc, count in zip(unique_classes, class_counts):\n",
    "        if uc != majority_class:\n",
    "            print(f\"Minority class: {uc.item()} with {count.item()} samples.\")\n",
    "    \n",
    "    return X_majority, X_minority\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Separate into majority and minority class \n",
    "X_majority, X_minority = prepare_data(features, labels)\n",
    "\n",
    "# Perform k-nearest neighbors\n",
    "k = 3\n",
    "generated_samples = augment_data(X_majority, X_minority, k)\n",
    "\n",
    "\n",
    "generated_samples_tensors = [torch.tensor(np.concatenate(gen_class)) for gen_class in generated_samples]\n",
    "\n",
    "\n",
    "print(\"Generated samples:\", generated_samples_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
